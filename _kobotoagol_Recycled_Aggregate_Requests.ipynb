{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5da0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requirements \n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from arcgis.gis import GIS\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.features import FeatureSet, GeoAccessor\n",
    "from arcgis.geometry import Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4a2f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import external files\n",
    "governorate_municipality = gpd.read_file(\".gpkg/UNEP_Gaza_Governorate_Municipality_Singleparts_POINTS.gpkg\")\n",
    "governorate_municipality = governorate_municipality.to_crs(epsg=4326)\n",
    "governorate_municipality.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12a2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication credentials\n",
    "KOBO_USERNAME = \"guilherme_iablonovski\"\n",
    "KOBO_PASSWORD = \"k0b0Senha\"\n",
    "export_token = \"f72722c6ffe97db14144325853528a4b7a1c059b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21577cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recycled Aggregate Request API endpoint\n",
    "kobo_api_url = \"https://kf.kobotoolbox.org/api/v2/assets/akPnoN3KN4wL7TyuPzHGLu/export-settings/es5Y32GjEiU7qFtbAuei965\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f93bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joses\\AppData\\Local\\Temp\\ipykernel_17556\\399000899.py:15: FutureWarning: Passing bytes to 'read_excel' is deprecated and will be removed in a future version. To read from a byte string, wrap it in a `BytesIO` object.\n",
      "  kobo_data = pd.read_excel(response.content)\n"
     ]
    }
   ],
   "source": [
    "def getKoboForm(url):\n",
    "    # Create a session with authentication\n",
    "    session = requests.Session()\n",
    "    session.auth = (KOBO_USERNAME, KOBO_PASSWORD)\n",
    "\n",
    "    # Construct the export URL\n",
    "    kobo_export_url = f\"{url}/data.xlsx\"#?format=csv&token={export_token}\"\n",
    "\n",
    "    # Fetch data using the authenticated session\n",
    "    response = session.get(kobo_export_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Load data into a pandas DataFrame\n",
    "        kobo_data = pd.read_excel(response.content)\n",
    "        kobo_data.head()\n",
    "        return kobo_data\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        \n",
    "kobo_data = getKoboForm(kobo_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbff6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica as colunas que começam com \"Please specify the municipality\"\n",
    "cols = [c for c in kobo_data.columns if c.startswith(\"Please specify the municipality\")]\n",
    "\n",
    "# Cria uma lista para armazenar os registros explodidos\n",
    "records = []\n",
    "\n",
    "# Itera sobre cada linha e coluna dessas\n",
    "for _, row in kobo_data.iterrows():\n",
    "    base_data = {col: row[col] for col in kobo_data.columns if col not in cols}  # mantém outras colunas\n",
    "\n",
    "    for col in cols:\n",
    "        val = row[col]\n",
    "        if pd.isna(val):\n",
    "            continue\n",
    "\n",
    "        # Extrai o nome entre parênteses\n",
    "        match = re.search(r'\\((.*?)\\)', col)\n",
    "        governo = match.group(1).strip() if match else ''\n",
    "\n",
    "        # Divide as respostas usando \". \" como separador\n",
    "        municipios = re.split(r'(?<=\\.)\\s+', str(val).strip())\n",
    "\n",
    "        # Limpa e forma a nova lista com \"Governo_Município\"\n",
    "        for m in municipios:\n",
    "            m = m.strip().rstrip('.')\n",
    "            if m:\n",
    "                new_row = base_data.copy()\n",
    "                new_row['Gov_Mun'] = f\"{governo}_{m}\"\n",
    "                records.append(new_row)\n",
    "\n",
    "# Cria o novo DataFrame com as linhas expandidas\n",
    "kobo_data_exploded = pd.DataFrame(records).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf603a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INITIAL CLEANING\n",
    "\n",
    "#Standardize data for municipalities without neighborhoods\n",
    "\n",
    "def standardize(df):\n",
    "\n",
    "    kobo_data_0 = df.replace(0, None)  \n",
    "    return kobo_data_0\n",
    "\n",
    "kobo_data_exploded = standardize(kobo_data_exploded)\n",
    "\n",
    "# Faz o join com o gdf, mantendo todos os municípios originais\n",
    "\n",
    "gdf_filtrado = governorate_municipality.merge(kobo_data_exploded, on='Gov_Mun', how='right')\n",
    "\n",
    "# Create string column to 'submission_time'\n",
    "gdf_filtrado[\"hora_subm\"] = (\n",
    "    gdf_filtrado[\"_submission_time\"]\n",
    "    .astype(\"datetime64[ns]\")\n",
    "    .dt.strftime(\"%Y-%m-%d %H:%M\")   # Ou outro formato que preferir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720ee01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\object_array.py:172: FutureWarning: Possible nested set at position 1\n",
      "  pat = re.compile(pat, flags=flags)\n"
     ]
    }
   ],
   "source": [
    "#Handle columns so they are not modified by arcgis when uploaded\n",
    "def makeArcGISfriendly(df):\n",
    "    df.columns = df.columns.str.replace(r\"[ ]\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[.]\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[?]\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[']\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[(]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[)]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[[]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[]]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[%]\", \"_\", regex=True)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    # Remove leading underscores\n",
    "    df = df.rename(columns={\n",
    "        '_id':'f_id',\n",
    "        '_uuid':'f_uuid',\n",
    "    })\n",
    "    df.columns = df.columns.str.lstrip('_')\n",
    "    \n",
    "    #Truncate and ensure uniqueness\n",
    "    seen = {}\n",
    "    final_cols = []\n",
    "    max_length = 31\n",
    "    for col in df.columns:\n",
    "        base = col[:max_length]\n",
    "        new_col = base\n",
    "        i = 1\n",
    "        while new_col in seen:\n",
    "            suffix = f\"_{i}\"\n",
    "            trim_len = max_length - len(suffix)\n",
    "            new_col = base[:trim_len] + suffix\n",
    "            i += 1\n",
    "        seen[new_col] = True\n",
    "        final_cols.append(new_col)\n",
    "    \n",
    "    # Step 4: Apply to DataFrame\n",
    "    df.columns = final_cols\n",
    "    return df\n",
    "\n",
    "gdf_exploded = makeArcGISfriendly(gdf_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1b97d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joses\\AppData\\Local\\Temp\\ipykernel_17556\\3003421674.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df['geometry'] = df['geometry'].centroid\n"
     ]
    }
   ],
   "source": [
    "def simplifyGeometries(df):\n",
    "    df['geometry'] = df['geometry'].centroid\n",
    "    return df\n",
    "    \n",
    "gdf_exploded = simplifyGeometries(gdf_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "unique_flags = []\n",
    "\n",
    "for _, row in gdf_exploded.iterrows():\n",
    "    if row['f_id'] in seen:\n",
    "        unique_flags.append('')\n",
    "    else:\n",
    "        unique_flags.append('yes')\n",
    "        seen.add(row['f_id'])\n",
    "\n",
    "gdf_exploded['unique_'] = unique_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e8115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean columns\n",
    "gdf_colunas = gdf_exploded[['objectid', 'neighborhood', 'municipality', 'governorate', 'arabicname', 'governate_name',\n",
    "       'municipality_name', 'neighborhood_name', 'location_gdf', 'gov_mun',\n",
    "       'geometry', 'requesting_agency', 'please_specify', 'contact_person_name', 'contact_person_phone_number',\n",
    "       'contact_person_email_address', 'location_of_planned_interventio',\n",
    "       'intended_use_of_recycled_materi', 'please_specify_1',\n",
    "       'requested_quantity', 'specify_the_measurement_unit', 'hora_subm',\n",
    "       'f_id', 'f_uuid', 'submission_time', 'status', 'submitted_by', 'version__', 'tags', 'index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c67eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repair columns names\n",
    "gdf_colunas.columns = (\n",
    "    gdf_colunas.columns\n",
    "      .str.normalize('NFKD')\n",
    "      .str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "      .str.replace('[^0-9a-zA-Z_]+', '_', regex=True)\n",
    "      .str.replace('^[0-9]+', '', regex=True)\n",
    "      .str.strip('_')\n",
    ")\n",
    "\n",
    "gdf_colunas = gdf_colunas.rename(columns={'': 'empty_field'})\n",
    "\n",
    "gdf_colunas = gdf_colunas.rename(columns={\n",
    "    'location_of_planned_interventio': 'planned_intervention',\n",
    "    'intended_use_of_recycled_materi': 'use_of_recycled_material'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2ddc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitar cada nome a 31 caracteres\n",
    "gdf_colunas.columns = [c[:31] for c in gdf_colunas.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9645cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UPDATE DATA IN ARCGIS\n",
    "\n",
    "#Connect to the ArcGIS Enterprise portal\n",
    "\n",
    "AGOL_USERNAME = 'h.partow'\n",
    "AGOL_PASSWORD = 'R&Runit2024'\n",
    "gis = GIS('https://wesrmapportal.unep.org/portal/', AGOL_USERNAME, AGOL_PASSWORD)\n",
    "\n",
    "# Access the feature-layer through its URL\n",
    "file = \"https://wesrmapportal.unep.org/arcgis/rest/services/Hosted/DWG_Gaza_Aggregate_for_Recycling/FeatureServer\"\n",
    "\n",
    "# Access the feature-layer through its URL\n",
    "agg_file = 'DWG_Gaza_Aggregate_for_Recycling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a298ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchArcgis(keyword):\n",
    "    if not isinstance(keyword, str):\n",
    "        raise TypeError(f\"Esperado 'str' em 'keyword', recebido {type(keyword)} → {keyword}\")\n",
    "    results = gis.content.search(f'title:\\\"{keyword}\\\"', item_type=\"Feature Layer\")\n",
    "    if not results:\n",
    "        print(\"Nenhum resultado encontrado para\", keyword)\n",
    "        return None\n",
    "    results_sorted = sorted(results, key=lambda x: x.modified, reverse=True)\n",
    "    return results_sorted[0]\n",
    "\n",
    "search_agg = searchArcgis(agg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8f6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFeature(search_results, gdf):\n",
    "\n",
    "    item = gis.content.get(search_results.id)\n",
    "\n",
    "    flc = FeatureLayerCollection.fromitem(item)\n",
    "    layer = flc.layers[0]  # Assuming you're working with the first layer\n",
    "\n",
    "\n",
    "    # Step 1: Truncate features\n",
    "    truncate_result = layer.manager.truncate()\n",
    "    print(\"Truncate result:\", truncate_result)\n",
    "\n",
    "    # Keep only matching columns\n",
    "    expected_fields = [f[\"name\"] for f in layer.properties.fields if f[\"name\"] != \"fid\"]\n",
    "    gdf = gdf[[col for col in gdf.columns if col in expected_fields or col == \"geometry\"]]\n",
    "\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    sedf = GeoAccessor.from_geodataframe(gdf)\n",
    "\n",
    "    fs = FeatureSet.from_dataframe(sedf)\n",
    "\n",
    "    result = layer.edit_features(adds=fs.features)\n",
    "    print(\"Result:\", result)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1445a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correção de colunas\n",
    "# Campos que devem ser double\n",
    "double_fields = [\"please_specify_1\", \"empty_field\"]\n",
    "\n",
    "for col in double_fields:\n",
    "    if col in gdf_colunas.columns:\n",
    "        gdf_colunas[col] = pd.to_numeric(gdf_colunas[col], errors=\"coerce\")\n",
    "\n",
    "# Campo que precisa ser string\n",
    "if \"contact_person_phone_number\" in gdf_colunas.columns:\n",
    "    gdf_colunas[\"contact_person_phone_number\"] = (\n",
    "        gdf_colunas[\"contact_person_phone_number\"].astype(str)\n",
    "    )\n",
    "\n",
    "# Campos big integer → garantir int\n",
    "bigint_fields = [\"requested_quantity\", \"index\", \"f_id\"]\n",
    "for col in bigint_fields:\n",
    "    if col in gdf_colunas.columns:\n",
    "        gdf_colunas[col] = gdf_colunas[col].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd3bb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_problema = [\n",
    "    \"please_specify_1\",\n",
    "    \"requested_quantity\",\n",
    "    \"f_id\",\n",
    "    \"submitted_by\",\n",
    "    \"tags\",\n",
    "    \"index\"\n",
    "]\n",
    "\n",
    "gdf_colunas = gdf_colunas.drop(columns=cols_problema, errors=\"ignore\").copy()\n",
    "gdf_colunas[\"SHAPE\"] = gdf_colunas.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48cf535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncate result: {'success': True}\n",
      "Result: {'addResults': [{'success': True, 'objectId': 1}, {'success': True, 'objectId': 2}, {'success': True, 'objectId': 3}, {'success': True, 'objectId': 4}, {'success': True, 'objectId': 5}, {'success': True, 'objectId': 6}, {'success': True, 'objectId': 7}, {'success': True, 'objectId': 8}, {'success': True, 'objectId': 9}, {'success': True, 'objectId': 10}, {'success': True, 'objectId': 11}, {'success': True, 'objectId': 12}, {'success': True, 'objectId': 13}, {'success': True, 'objectId': 14}, {'success': True, 'objectId': 15}, {'success': True, 'objectId': 16}, {'success': True, 'objectId': 17}, {'success': True, 'objectId': 18}, {'success': True, 'objectId': 19}, {'success': True, 'objectId': 20}, {'success': True, 'objectId': 21}], 'updateResults': [], 'deleteResults': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'addResults': [{'success': True, 'objectId': 1},\n",
       "  {'success': True, 'objectId': 2},\n",
       "  {'success': True, 'objectId': 3},\n",
       "  {'success': True, 'objectId': 4},\n",
       "  {'success': True, 'objectId': 5},\n",
       "  {'success': True, 'objectId': 6},\n",
       "  {'success': True, 'objectId': 7},\n",
       "  {'success': True, 'objectId': 8},\n",
       "  {'success': True, 'objectId': 9},\n",
       "  {'success': True, 'objectId': 10},\n",
       "  {'success': True, 'objectId': 11},\n",
       "  {'success': True, 'objectId': 12},\n",
       "  {'success': True, 'objectId': 13},\n",
       "  {'success': True, 'objectId': 14},\n",
       "  {'success': True, 'objectId': 15},\n",
       "  {'success': True, 'objectId': 16},\n",
       "  {'success': True, 'objectId': 17},\n",
       "  {'success': True, 'objectId': 18},\n",
       "  {'success': True, 'objectId': 19},\n",
       "  {'success': True, 'objectId': 20},\n",
       "  {'success': True, 'objectId': 21}],\n",
       " 'updateResults': [],\n",
       " 'deleteResults': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateFeature(search_agg, gdf_colunas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
