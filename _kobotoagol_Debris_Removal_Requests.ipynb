{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890555e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requirements \n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from io import BytesIO\n",
    "from arcgis.gis import GIS\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.features import FeatureSet, GeoAccessor\n",
    "from arcgis.geometry import Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import external files\n",
    "governorate_municipality = gpd.read_file(\".gpkg/UNEP_GazaNeighborhoods_Location_Singleparts.gpkg\")\n",
    "governorate_municipality = governorate_municipality.to_crs(epsg=4326)\n",
    "governorate_municipality.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication credentials\n",
    "KOBO_USERNAME = \"guilherme_iablonovski\"\n",
    "KOBO_PASSWORD = \"k0b0Senha\"\n",
    "export_token = \"f72722c6ffe97db14144325853528a4b7a1c059b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recycled Aggregate Request API endpoint\n",
    "kobo_api_url = \"https://kf.kobotoolbox.org/api/v2/assets/aovraeDJBEKefJnHS2Ghiy/export-settings/esee5sgUTcwNESxJG7rUBHi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5402993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKoboForm(url):\n",
    "    # Create a session with authentication\n",
    "    session = requests.Session()\n",
    "    session.auth = (KOBO_USERNAME, KOBO_PASSWORD)\n",
    "\n",
    "    # Construct the export URL\n",
    "    kobo_export_url = f\"{url}/data.xlsx\"#?format=csv&token={export_token}\"\n",
    "\n",
    "    # Fetch data using the authenticated session\n",
    "    response = session.get(kobo_export_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Load data into a pandas DataFrame\n",
    "        kobo_data = pd.read_excel(BytesIO(response.content))\n",
    "        kobo_data.head()\n",
    "        return kobo_data\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        \n",
    "kobo_data = getKoboForm(kobo_api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31703d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize data for municipalities without neighborhoods\n",
    "\n",
    "def standardize(df):\n",
    "\n",
    "    kobo_data_0 = df.replace(0, None)\n",
    "    kobo_data_0.columns = kobo_data_0.columns.str.replace('Please specify the neighbourhood', '').str.strip()\n",
    "\n",
    "\n",
    "    #Create fields for the municipalities that don't have follow-up neighborhood questions\n",
    "\n",
    "    kobo_data_0['(Deir Al-Balah / Al Maghazi)'] = None\n",
    "    kobo_data_0.loc[kobo_data_0['Please specify the municipality (Deir Al-Balah)'].astype(str).str.contains('Al Maghazi'), \n",
    "           '(Deir Al-Balah / Al Maghazi)'] = 'Al Maghazi Camp'\n",
    "\n",
    "\n",
    "    kobo_data_0['(Deir Al-Balah / Al Qarara)'] = None\n",
    "    kobo_data_0.loc[kobo_data_0['Please specify the municipality (Deir Al-Balah)'].astype(str).str.contains('Al Qarara'), \n",
    "           '(Deir Al-Balah / Al Qarara)'] = 'Smeiri'\n",
    "\n",
    "    kobo_data_0['(Gaza / Al Bureij)'] = None\n",
    "    kobo_data_0.loc[kobo_data_0['Please specify the municipality (Gaza)'].astype(str).str.contains('Al Bureij'), \n",
    "           '(Gaza / Al Bureij)'] = 'Al Bureij'\n",
    "\n",
    "    kobo_data_0['(Khan Younis / Al-Nnaser (Al Bayuk)'] = None\n",
    "    kobo_data_0.loc[\n",
    "        kobo_data_0['Please specify the municipality (Khan Younis)'].astype(str).str.contains('Al-Nnaser \\(Al Bayuk\\)', case=False, na=False),\n",
    "        '(Khan Younis / Al-Nnaser (Al Bayuk))'\n",
    "    ] = 'Umm Kameil'\n",
    "\n",
    "    kobo_data_0['(North Gaza / Um Al-NASER)'] = None\n",
    "    kobo_data_0.loc[\n",
    "        kobo_data_0['Please specify the municipality (North Gaza)'].astype(str).str.contains('Um Al-NASER', case=False, na=False),\n",
    "        '(North Gaza / Um Al-NASER)'\n",
    "    ] = 'Al Qaraya al Badawiya al Maslakh'\n",
    "\n",
    "\n",
    "    kobo_data_0['(Rafah / Al-Nnaser (Al Bayuk))'] = None\n",
    "    kobo_data_0.loc[\n",
    "        kobo_data_0['Please specify the municipality (Rafah)'].astype(str).str.contains('Al-Nnaser \\(Al Bayuk\\)', case=False, na=False),\n",
    "        '(Rafah / Al-Nnaser (Al Bayuk))'\n",
    "    ] = 'An Nasr'\n",
    "    \n",
    "    return kobo_data_0\n",
    "\n",
    "kobo_data = standardize(kobo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9750b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumns(df):\n",
    "\n",
    "    kobo_data_filter_NA = df.dropna(axis=1, how='all')\n",
    "    print(kobo_data_filter_NA.columns)\n",
    "\n",
    "    for coluna in kobo_data_filter_NA.columns:\n",
    "        if coluna.startswith('('):  # Verifica se a coluna começa com '('\n",
    "            kobo_data_filter_NA[coluna] = kobo_data_filter_NA[coluna].where(\n",
    "                kobo_data_filter_NA[coluna].isna(),  # Condição: mantém onde é NaN\n",
    "                coluna + \"_\" + kobo_data_filter_NA[coluna].astype(str)  # Substitui o resto\n",
    "            )\n",
    "\n",
    "    # Lista das colunas que começam com 'Location' ou 'Please'\n",
    "    colunas_para_remover = [\n",
    "        col for col in kobo_data_filter_NA.columns \n",
    "        if col.startswith(('Location', 'Please'))\n",
    "    ]\n",
    "\n",
    "    print(\"Preparing to remove \"+ str(colunas_para_remover))\n",
    "\n",
    "    # Remove as colunas do DataFrame\n",
    "    kobo_data_filter_NA = kobo_data_filter_NA.drop(columns=colunas_para_remover)\n",
    "    print(kobo_data_filter_NA.columns)\n",
    "\n",
    "    cols_para_destrinchar = [col for col in kobo_data_filter_NA.columns if str(kobo_data_filter_NA[col].iloc[0]).startswith('(')]\n",
    "\n",
    "    new_df = pd.DataFrame(columns=kobo_data_filter_NA.columns)\n",
    "\n",
    "\n",
    "\n",
    "    for _, row in kobo_data_filter_NA.iterrows():\n",
    "        # Verificamos se a linha contém valores que começam com '(' nas colunas selecionadas\n",
    "        if any(str(row[col]).startswith('(') for col in cols_para_destrinchar):\n",
    "            # Para cada coluna que começa com '(', criamos uma nova linha\n",
    "            for col in cols_para_destrinchar:\n",
    "                if str(row[col]).startswith('('):\n",
    "                    nova_linha = row.copy()\n",
    "                    # Mantemos apenas a coluna atual preenchida, as outras ficam nulas\n",
    "                    for other_col in cols_para_destrinchar:\n",
    "                        if other_col != col:\n",
    "                            nova_linha[other_col] = np.nan\n",
    "                    new_df = pd.concat([new_df, pd.DataFrame([nova_linha])], ignore_index=True)\n",
    "        else:\n",
    "            # Se a linha não tem valores que começam com '(', apenas adicionamos ao novo DataFrame\n",
    "            new_df = pd.concat([new_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "novo_df = removeColumns(kobo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the just-uploaded neighborhood mapping file\n",
    "neigh_map = pd.read_csv(\"Referencias/Caminho bairros - Página3.csv\")\n",
    "\n",
    "# Clean and extract all valid neighborhoods\n",
    "neigh_map[['Governorate', 'Municipality']] = neigh_map[['Governorate', 'Municipality']].fillna(method='ffill')\n",
    "valid_neighborhoods = neigh_map['Neighborhood'].dropna().unique().tolist()\n",
    "valid_neigh_lower = [n.lower().strip() for n in valid_neighborhoods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df):\n",
    "\n",
    "    # Identify all (Governorate / Municipality) columns\n",
    "    location_cols = [col for col in df.columns if col.startswith(\"(\")]\n",
    "\n",
    "    # Updated location extraction function with fallback when neighborhoods aren't matched\n",
    "    def extract_locations(row):\n",
    "        locations = []\n",
    "        for col in location_cols:\n",
    "            val = row.get(col)\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            try:\n",
    "                gov_mun, neigh_part = val.split('_', 1)\n",
    "            except ValueError:\n",
    "                # No neighborhood string at all\n",
    "                locations.append(col.strip())\n",
    "                continue\n",
    "\n",
    "            matched_any = False\n",
    "            words = neigh_part.strip().split()\n",
    "            idx = 0\n",
    "            while idx < len(words):\n",
    "                for end in range(len(words), idx, -1):\n",
    "                    candidate = ' '.join(words[idx:end])\n",
    "                    if candidate.lower().strip() in valid_neigh_lower:\n",
    "                        locations.append(f'{gov_mun}_{candidate}')\n",
    "                        idx = end - 1\n",
    "                        matched_any = True\n",
    "                        break\n",
    "                idx += 1\n",
    "\n",
    "            if not matched_any:\n",
    "                locations.append(col.strip())  # Fallback if no neighborhood matched\n",
    "        return locations\n",
    "\n",
    "    # Apply and explode\n",
    "    df['location_list'] = df.apply(extract_locations, axis=1)\n",
    "    df_exploded = df.explode('location_list').rename(columns={'location_list': 'location_1'})\n",
    "    df_exploded = df_exploded[df_exploded['location_1'].notna() & (df_exploded['location_1'] != '')]\n",
    "    return df_exploded.reset_index()\n",
    "\n",
    "df_exploded = explode(novo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the geodataframes and merge then\n",
    "gaza_neighborhoods = gpd.read_file('.gpkg/UNEP_GazaNeighborhoods_Location_Singleparts.gpkg')\n",
    "\n",
    "gaza_neighborhoods['location_id'] = (\n",
    "    '(' + gaza_neighborhoods['Governorate'].astype(str).str.strip() + ' / ' +\n",
    "    gaza_neighborhoods['Municipality'].astype(str).str.strip() + ')_' +\n",
    "    gaza_neighborhoods['Neighborhood'].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "\n",
    "gaza_cities = gaza_neighborhoods.dissolve(by='Municipality').reset_index()\n",
    "gaza_cities = gaza_cities[['Municipality','Governorate','geometry']]\n",
    "gaza_cities['location_id'] = (\n",
    "    '(' + gaza_cities['Governorate'].astype(str).str.strip() + ' / ' +\n",
    "    gaza_cities['Municipality'].astype(str).str.strip() + ')'\n",
    ")\n",
    "gaza_cities\n",
    "\n",
    "\n",
    "gaza_neighborhoods = pd.concat([gaza_neighborhoods, gaza_cities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge it to the exploded data\n",
    "gdf_exploded = gaza_neighborhoods[['location_id','geometry','Neighborhood','Municipality','Governorate']].merge(df_exploded, how='inner', left_on='location_id', right_on='location_1')\n",
    "\n",
    "# Lista das colunas que começam com 'Location' ou 'Please'\n",
    "colunas_para_remover = [\n",
    "    col for col in gdf_exploded.columns \n",
    "    if col.startswith(('(','location_1'))\n",
    "]\n",
    "\n",
    "# Remove as colunas do DataFrame\n",
    "gdf_exploded = gdf_exploded.drop(columns=colunas_para_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_exploded['hora_subm'] = gdf_exploded['_submission_time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle columns so they are not modified by arcgis when uploaded\n",
    "def makeArcGISfriendly(df):\n",
    "    df.columns = df.columns.str.replace(r\"[ ]\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[.]\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[?]\", \"_\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[']\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[(]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[)]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[[]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[]]\", \"\", regex=True)\n",
    "    df.columns = df.columns.str.replace(r\"[%]\", \"_\", regex=True)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    # Remove leading underscores\n",
    "    df = df.rename(columns={\n",
    "        '_id':'f_id',\n",
    "        '_uuid':'f_uuid',\n",
    "        'expected_start_date':'start_date',\n",
    "        'expected_end_date':'end_date'\n",
    "    })\n",
    "    df.columns = df.columns.str.lstrip('_')\n",
    "    #Truncate and ensure uniqueness\n",
    "    seen = {}\n",
    "    final_cols = []\n",
    "    max_length = 31\n",
    "    for col in df.columns:\n",
    "        base = col[:max_length]\n",
    "        new_col = base\n",
    "        i = 1\n",
    "        while new_col in seen:\n",
    "            suffix = f\"_{i}\"\n",
    "            trim_len = max_length - len(suffix)\n",
    "            new_col = base[:trim_len] + suffix\n",
    "            i += 1\n",
    "        seen[new_col] = True\n",
    "        final_cols.append(new_col)\n",
    "    \n",
    "    # Step 4: Apply to DataFrame\n",
    "    df.columns = final_cols\n",
    "    return df\n",
    "\n",
    "gdf_exploded = makeArcGISfriendly(gdf_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c854a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplifyGeometries(df):\n",
    "    df['geometry'] = df['geometry'].centroid\n",
    "    return df\n",
    "    \n",
    "gdf_exploded = simplifyGeometries(gdf_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d290cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_exploded.to_file('DWG_Gaza_Removal_Debris_Requests.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7260803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UPDATE DATA IN ARCGIS\n",
    "\n",
    "#Connect to the ArcGIS Enterprise portal\n",
    "\n",
    "AGOL_USERNAME = 'h.partow'\n",
    "AGOL_PASSWORD = 'R&Runit2024'\n",
    "gis = GIS('https://wesrmapportal.unep.org/portal/', AGOL_USERNAME, AGOL_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2366240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature-layer through its URL\n",
    "file = \"https://wesrmapportal.unep.org/arcgis/rest/services/Hosted/DWG_Gaza_Removal_Debris_Requests/FeatureServer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537353f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature-layer through its URL\n",
    "agg_file = 'DWG_Gaza_Removal_Debris_Requests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchArcgis(keyword):\n",
    "    if not isinstance(keyword, str):\n",
    "        raise TypeError(f\"Esperado 'str' em 'keyword', recebido {type(keyword)} → {keyword}\")\n",
    "    results = gis.content.search(f'title:\\\"{keyword}\\\"', item_type=\"Feature Layer\")\n",
    "    if not results:\n",
    "        print(\"Nenhum resultado encontrado para\", keyword)\n",
    "        return None\n",
    "    results_sorted = sorted(results, key=lambda x: x.modified, reverse=True)\n",
    "    return results_sorted[0]\n",
    "\n",
    "search_agg = searchArcgis(agg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ab7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateFeature(search_results, gdf):\n",
    "\n",
    "    item = gis.content.get(search_results.id)\n",
    "\n",
    "    flc = FeatureLayerCollection.fromitem(item)\n",
    "    layer = flc.layers[0]  # Assuming you're working with the first layer\n",
    "\n",
    "\n",
    "    # Step 1: Truncate features\n",
    "    truncate_result = layer.manager.truncate()\n",
    "    print(\"Truncate result:\", truncate_result)\n",
    "\n",
    "    # Keep only matching columns\n",
    "    expected_fields = [f[\"name\"] for f in layer.properties.fields if f[\"name\"] != \"fid\"]\n",
    "    gdf = gdf[[col for col in gdf.columns if col in expected_fields or col == \"geometry\"]]\n",
    "\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    sedf = GeoAccessor.from_geodataframe(gdf)\n",
    "\n",
    "    fs = FeatureSet.from_dataframe(sedf)\n",
    "\n",
    "    result = layer.edit_features(adds=fs.features)\n",
    "    print(\"Result:\", result)\n",
    "    return(result)\n",
    "\n",
    "updateFeature(search_agg, gdf_exploded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
